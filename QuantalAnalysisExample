%Exercise 1
%To find this I want an array of the probabilities that there will be 1, 2,...10 quanta released 
%when there are 10 available quanta and the release probability is 0.2
%Note that to form the array, the values we're going to be evaluating are listed as exclusive of the first number
%but inclusive of the last number. Thus, 0:10 gives us 1-10 quanta.
probs = binopdf(0:10,10,0.2)
%Answers for pRelease 1-10 quanta given these parameters: 0.107, 0.268, 0.302, 0.088, 0.026, 0.006, 0.0008, 0.0001, 0.0, 0.0 
%for what it's worth, the most likely event is 3 quanta being released!
%%%
%Exercise 2
%This is the first question the opposite way: I know the number of quanta, 14; I know the outcome, 8 quanta released, 
%and I want the probability for each quartile. So, what I have is:
n=14 %number of quanta
k=8 %number of quanta that are RELEASED
%so, here are the probabilities that 8 quanta will be released if p = ...

prob01 = binopdf(k,n,0.1) %pRelease = 0.1 (prob=0.000015)
prob02 = binopdf(k,n,0.2)%pRelease = 0.2 (prob=0.0020)
prob03 = binopdf(k,n,0.3)%pRelease = 0.3 (prob=0.0232)
prob04 = binopdf(k,n,0.4)%pRelease = 0.4 (prob=0.0918)
prob05 = binopdf(k,n,0.5)%pRelease = 0.5 (prob=0.1833)
prob06 = binopdf(k,n,0.6)%pRelease = 0.6 (prob=0.2066) 
prob07 = binopdf(k,n,0.7)%pRelease = 0.7 (prob=0.1262)
prob08 = binopdf(k,n,0.8)%pRelease = 0.8 (prob=0.0322)
prob09 = binopdf(k,n,0.9)%pRelease = 0.9 (prob=0.0013)
prob1 = binopdf(k,n,1)%pRelease = 1 (prob=0, because 14 will be released if pRelease = 1 :D )
%This is the heart of maximum likelihood estimation. Finding the parameter that gives you the highest likelihood taht you would have gotten the data you got, GIVEN THE PARAMETER value you've found.
%Based on these numbers, pRelease=0.6 is the most probable
%%%
%Exercise 3
%Assume that these are INDEPENDENTTTT experiments
%Probability of 8 quanta released
prob1=(8,14,0.1)
%Probability of 5 quanta released
prob2=(5,14,0.1)
%probability of both events happening on two trials
Totprob = prob1 * prob2
%log of the probability - remember your highschool math, that multiplying logs is adding the logs of the multiplied numbers
LogTotprob = log(prob1) + log(prob2)
%For the rest of this question I got confused and used the code from the example solution
%For this block of code, we're looking at all of the likelihoods of these two events happening in tandem, when release probabiilty is from 0-10, 
%moving in steps of 0.1 (so, 0, 0.1, 0.2...) also I'll need the k1, k2, n1, n2 variables that I didn't use earlier for this question
k1=8
k2=5
n1=14
n2=14
%Note that bleow, we're fixing the p to different values...and finding the MAXIMUM computation, which is the MOST LIKELY reason you would have gotten this result :D 
%NOTE THAT FOR THIS TO BE MEANINGFUL YOU NEED TO ASSUME THAT THE MODEL YOURE WORKING WITH IS TRUE. THERE ARE NO PROBABILITIES ASSOCIATED WITH THE MODEL BECAUSE YOU'RE ASSUMING IT HAPPENS AND YOU'RE VAARYING IT TO TEST DIFFERENT ONES; WHICH ALLOWS YOU TO SELECT THE ONE MOST LIKELY TO PRODUCE THE DATA YOU SAW
% likelihood and log-likelihood functions for sample size = 2
ps = (0:0.01:1.0)';           % Array of possible release probabilities -- compute
                              % at a resolution of 0.01
nps = length(ps);             % Get length of array of values of p (should be 101, for 0-100 inclusive)
probs = binopdf( ....         % Get value of the binomial distribution for each
   repmat([k1 k2], nps, 1), ...  % combination of k, n, p. The output is a matrix
   repmat([n1 n2], nps, 1), ...  % with two rows: 1) n1, k1  2) n2, k2
   repmat(ps, 1, 2));            % columns are different values of p
  %Now I have an array telling me for each of those 100 pRelease values, what is the likelihood of the events happening for sample size = 1, or for sample size = 2
%Now to plot it...  
% The likelihood function is the product of likelihoods (assuming
% independence)
subplot(2,1,1); cla reset; hold on;
ylabel('Likelihood');
likelihoodFcn = prod(probs,2);   % Compute the product
plot(ps, likelihoodFcn);         % Plot it
maxLikelihood = max(likelihoodFcn); % Get the maximum likelihood, which matlab told me was 0.024
plot(ps(likelihoodFcn==maxLikelihood), maxLikelihood, 'ko');  
%can you improve the max likelihood by doing a higher resolution?
%You tell me!
  % likelihood and log-likelihood functions for sample size = 2
ps = (0:0.001:1.0)';           % Array of possible release probabilities -- compute
                              % at a resolution of 0.001. I edited this for 0.00001 and 0.0000001 as well, but then I broke Matlab.
nps = length(ps);             % Get length of array of values of p (should be 101, for 0-100 inclusive)
probs = binopdf( ....         % Get value of the binomial distribution for each
   repmat([k1 k2], nps, 1), ...  % combination of k, n, p. The output is a matrix
   repmat([n1 n2], nps, 1), ...  % with two rows: 1) n1, k1  2) n2, k2
   repmat(ps, 1, 2));            % columns are different values of p
  %Now I have an array telling me for each of those 100 pRelease values, what is the likelihood of the events happening for sample size = 1, or for sample size = 2
%Now to plot it...  
% The likelihood function is the product of likelihoods (assuming
% independence)
subplot(2,1,1); cla reset; hold on;
ylabel('Likelihood');
likelihoodFcn = prod(probs,2);   % Compute the product
plot(ps, likelihoodFcn);         % Plot it
maxLikelihood = max(likelihoodFcn); % Get the maximum likelihood, which matlab told me was 0.024
plot(ps(likelihoodFcn==maxLikelihood), maxLikelihood, 'ko');  
%The answer seems to be that yes
%you can increase the max likelihood - marginally. Via trial and error the highest I got was 0.02406

%What about sample size increases?
%Below code is from Josh's example.
%It doesn't look like we can get better estimates as we increase sample size. My code got stuck at 4 and that had a worse estimate - 0.022
n = 14;                       % number of available quanta
pRelease = 0.3;               % assumed probability of release
ks = 0:n;                     % possible values of k
ps = 0:0.01:1.0;              % possible release probabilities
pdat = zeros(length(ps), 2);  % pre-allocate matrix to hold likelihoods per p
TINY = 0.0001;                % to avoid multiplying/taking logs of really small numbers
for sampleSize = round(logspace(0,3,30))  % try different sample sizes
   
   % Simulate experiments -- get simulated counts for the given n,
   % pRelease, and number of experiments
   sCounts = binornd(n,pRelease,sampleSize,1);
   
   % Plot experiment, theoretical binomial pdf
   subplot(3,1,1); cla reset; hold on;
   title(sprintf('Sample size = %d', sampleSize))
   ylabel('Probability');
   xlabel('Release count');
   xlim([ks(1) ks(end)]);
   
   % Plot normalized histogram of simulated counts
   sCountHistogram = hist(sCounts, ks);
   bar(ks, sCountHistogram./sum(sCountHistogram));
   
   % Plot theoretical pdf
   plot(ks, binopdf(ks, n, pRelease), 'ro-');
   
   % compute (log) lik for each p
   pdat(:,1) = 1; % initialize so we can keep track of product of likelihoods
   pdat(:,2) = 0; % initialize so we can keep track of sum of log-likelihoods
   
   % Loop through each possible value of release probability
   for pp = 1:length(ps)
      
      % Compute the probabilities of obtaining the data, given the assumed
      % release probabilty
      probs = binopdf(ks, n, ps(pp));
      
      % Loop through each possible value of k we could have obtained in the
      % simulated experiment
      for cc = 1:length(ks)
         
         % Did we actually obtain that particular value of k?
         if sCountHistogram(cc) > 0
            
            % Avoid really small numbers
            if probs(cc) < TINY
               lprob = log(TINY);
               pprob = TINY;
            else
               lprob = log(probs(cc));
               pprob = probs(cc);
            end
            
            % Product of likelihoods
            pdat(pp,1) = pdat(pp,1).*pprob.^sCountHistogram(cc);
            
            % Sum of log likelihoods
            pdat(pp,2) = pdat(pp,2)+lprob.*sCountHistogram(cc);
         end
      end
   end
   
   % Use binofit to estimate p from the simulated data. This uses a trick
   % that assumes all of the measurements are independent and lumps them
   % together as if they were one big experiment.
   [phat, pci] = binofit(sum(sCounts),sampleSize*14);
   
   % Plot product of likelihoods
   %
   subplot(3,1,2); cla reset; hold on;
   ylabel('likelihood');

   % Plot the likelihood function (product of likelihoods)
   plot(ps, pdat(:,1));
   
   % Find the maximum
   maxp = max(pdat(:,1));
   
   % Show the actual pRelease value as a dashed line
   plot(pRelease.*[1 1], [0 maxp], 'r--');
   
   % Show the values obtained from binofit + CI
   plot(pci, maxp.*[1 1], 'm-', 'LineWidth', 2);
   plot(phat, maxp, 'm*');
   
   % Show the maximum value of our computed likelihood function
   plot(ps(pdat(:,1)==maxp), maxp, 'ko', 'MarkerSize', 12); 
   
   % plot sum of log-likelihoods
   %
   subplot(3,1,3); cla reset; hold on;
   ylabel('log likelihood');
   xlabel('Release probability');
   axis([0 1 log(TINY)*1000 0]);

   % Plot the likelihood function (sum of log-likelihoods)
   plot(ps, pdat(:,2));
   
   % Find the maximum
   maxp = max(pdat(:,2));
   
   % Show the actual pRelease value as a dashed line
   plot(pRelease.*[1 1], [0 min(pdat(:,2))], 'r--');
   
   % Show the values obtained from binofit + CI
   plot(pci, maxp.*[1 1], 'm-', 'LineWidth', 2);
   plot(phat, maxp, 'm*');

   % Show the maximum value of our computed likelihood function
   plot(ps(pdat(:,2)==maxp), maxp, 'g*'); 
   
   % Wait
   pause(0.1);
end

%So, yes, it does look like the estimates get closer to the theoretical one when we increase sample size.
%%%
%%%
%Exercise 4
%Stole this from Josh. This is beyond my capability at the moment :) 
% Note that like good Matlab programmers, we'll do this without loops
counts = [0	0 3 10 19 26 16 16 5 5 0 0 0 0 0]; % The experimental outcomes = I assume this is the absolute number of quanta available (k)
n = length(counts)-1;   % Number of available quanta in each experiment (in matlab speak, since we're putting it into a range...?)
ks = 0:n;               % Possible values of k, as a row vector
nks = length(ks);       % Length of k
ps = (0:0.01:1.0)';     % Possible values of release probability, as a column vector
nps = length(ps);       % Length of p

% Compute the value of the binomial distribution for each possible value of 
%  k, n, p. Make a matrix in which:
%     - columns correspond to different values of p
%     - rows correspond to different values of k
probs = binopdf( ...
   repmat(ks, nps, 1), ...    % Repeat ks-row vector for each p
   n, ...                     % Always assuming the same 'n'
   repmat(ps, 1, nks));       % Repeat ps-column vector for each k

% Make a matrix of outcomes (in rows) that are repeated along the columns so we can
% use them to compute likelihoods for each possible value of release probability (p)
countsMatrix = repmat(counts, nps, 1);

% Compute likelihood function, which takes the product of all likelihoods
% associated with each measured outcome. 
likelihoodFcn = prod(probs.^countsMatrix,2);
pHat_fromLiklihood = ps(likelihoodFcn==max(likelihoodFcn))

% Compute log-likelihood function, which takes the sum of all log-likelihoods
% associated with each measured outcome. 
logLikelihoodFcn = sum(log(probs).*countsMatrix,2);
pHat_fromLogLikelihood = ps(logLikelihoodFcn==max(logLikelihoodFcn))
 %pHat_fromLogLikelihood = 0.0300
% use binofit; used the binomial fit function as recommended in the exercise :)
pHat = binofit(sum(counts.*ks),sum(counts)*n)
 %pHat = 0.3821
%%%
%Exercise 5
n = 14;                       % Number of available quanta
k = 7;                        % Measured number of released quanta
pHat = binofit(k,n)           % Compute maximum-likelihood value of p (I'm getting 0.5)
pNull = 0.3;                  % Null hypothesis p (so, if null hypothesis is that prelease is not 0.3 we can't reject it b/c prob = 0.5)
prob = binopdf(k,n,pNull)    % p>0.05, so cannot rule out that we would have gotten this measurement by chance under the null hypothesis
  




%%Class notes
%Likelihood: p(data|model) where model is the parameters of a parametric distribution (e.g. n and p, here; data is k, I think?)
%Assume form of the model; given that assumed form, what's the probability that you would have gotten your data?
%Maximum likelihood estimation - you want to make your likelihood as high as possible
%p-value fitting is based ont he likelihood term



